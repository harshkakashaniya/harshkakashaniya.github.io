---
layout: default
title:
---

<section class="row-fluid">
<div class="plain-title">
      <div class="container">
        <div class="span12">
          <h1>Projects </h1>
	  <p>Following are the projects of different domains in Robotics.</p>
        </div>
      </div>
    </div>
<div class="Subject-title">
      <div class="container">
        <div class="span12">
          <h2>Robot Path planning </h2>
	  <p>This section includes projects on motion planning of mobile robot and manupulators. </p>
        </div>
      </div>
    </div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Solution to Metric Travelling Salesman Problem </font></h3>
    <h3><font color="white"> Prog. Language. Used: Python </font> </h3>
    <h3><font color="white">Keywords: Combinatorial optimization, TSP, MST, Dictionary, DFS</h3>
    <p> NP Hard and Combinatorial optimization are terms easier to express in theory than in code. The Travelling Salesman Problem is one such and has involved a lot of reasearch in the past. In this project, I refer to cities as nodes that the robot needs to visit. The goal is to form a tour such that the robot visits all the nodes taking the shortest possible route, in other words an optimized planner which creates the route such that the sum of the cost to travel between the nodes is minimum.</p> 
<p><font color="white">
To solve this I used Depth First Search (DFS) applied on the Minimum Spannning Tree (MST) based on the 2-approximation algorithm. As the name implies the cost of the MST i.e the sum of the weights of all the edges in the tree is the minimum possible among all possible spanning trees. The edge weight between the nodes is the Euclidian distance. The MST is created by basically connecting the nearest neighbour from each node/vertex, while simulataneously avoiding any loops. This is achived by making the MST dictionary in a directed fashion such that the edges are always directed from a visited node to an unvisited node. DFS is then used to form a stack to keep track of all the childs of each parent of the tree.</font></p> 

<p>
The above technique gives us a basic tour which needs to be optimized using a combination of various heuristics. Various algorithms have been used for the same such as the 2-opt, nearest neighbour switch, reverse order swapping of nodes etc. This have been explained and proved in the BLOG link below.   </font></p>
<a href="https://github.com/harshkakashaniya/Travelle ing_Salesman_problem" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a>  

    </div>
    <div class="span5">
      <img src="./img/TSP.png" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Left-project">

<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
      <img src="./img/A_diff.png" alt="" title="" class="sidebar__image" />
    </div>
    <div class="span5">
    <h3>Implementation of path planning algorithms on normal and differential constraints using turtle bot</h3>
<h3>Prog. Lang. Used: Python ,VREP  </h3>
    <h3>Keywords: Robot Path planning, Dijkstra , A* ,Differential Constraints</h3>
    <p>Autonomous robot path planning is important for various applications. In the real world, robots move through space in a continous fashion and not discreate. Hence considering differential constraints is necessary. In this project Dijkstra and A* robot path planning algorithms have been implemented using the above constraints. The start and goal nodes was given as inputs to the algorithm along with the wheel radius. The path was generated along with the wheel RPMs to form the trajectory. This output was fed to VRep. The turtlebot was seen traversing successfully along the path from the start to the goal node in an indoor static environment as shown.</p> 
<a href="https://github.com/harshkakashaniya/A_star_with_differential_constraints-" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a>  
   
</div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">8-Puzzle-Solver</font></h3>
    <h3><font color="white"> Prog. Language. Used: Python </font> </h3>
    <h3><font color="white">Keywords: Puzzle Solver, DFS , BFS</h3>
    <p><font color="white">This project uses BFS algorithm to calculate all possible configurations space till it reaches goal state. This project is impelemented using queue and matrices as the data structures. It also has two approaches which is time complexity and space complexity.Provide your own custom input and try out the algorithm. </font></p>
<a href="https://github.com/harshkakashaniya/8-Puzzle-Solver" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a>  

    </div>
    <div class="span5">
      <img src="./img/8puzzle.png" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Left-project">

<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
      <img src="./img/Frontier_Exp.png" alt="" title="" class="sidebar__image" />
    </div>
    <div class="span5">
    <h3><font color="Black">Frontier Exploration with Turtle Bot<font></h3>
<h3>Prog. Lang. Used: C++ , ROS , PCL </h3>
    <h3>Keywords: Unknown Exploration, Gazebo , Rviz</h3>
    <p>Prometheus is a frontier exploration package in ROS. Frontier exploration is the method of exploring unknown environments autonomously. Prometheus uses the turtlebot platform for simulation and implementing the frontier exploration package.</p>
<p>We used pair programming for all the design and development purpose. The planning and development of this module were split into three sprints of a week each. The product backlog, work log and iteration log can be found in the link below. Test Driven Development approach is taken for implementation and unit testing. </p> 
<a href="https://github.com/harshkakashaniya/prometheus_frontier_explorer" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a>  
   
</div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Roadmap Based Robot Motion Planning in Dynamic Environments</font></h3>
    <h3><font color="white">Prog. Lang. Used: Python </font></h3>
    <h3><font color="white">Keywords: Dynamic Planning, PRM, State Time Space, A*, KD Tree</font></h3>
    <p><font color="white">Path Planning of mobile robots in an environment which encompasses both dynamic and static obstacles reamains to be a challenging task. Here a pragmatic algorithm based  on the roadmap for the static part of the scene is first developed. The roadmap generated is used to form a time-optimal trajectory from start position to goal position without colliding with the non-static obstacle. This is achieved using the PRM algorithm which takes random samples from the configuration space of the robot, tests them for whether they are in the free space, and uses a local planner to attempt to connect these configurations to other nearby configurations. The starting and goal configurations are added in, and a graph search algorithm is applied to the resulting graph to determine a path between the starting and goal configurations.</font></p>       

<p><font color="white">
The final path is obtained in two phases; the first phase is the local level search where a sub-optimal trajectory is developed using the depth-first search (DFS) and in the following phase, an optimal path is obtained taking in consideration time as one of the parameters and using A* search algorithm.  The solution obtained is applicable to all types of robots, in any configuration space where the motion of obstacles is unconstrained but should be known beforehand. Furthermore, the velocities of obstacle also should remain constant throughout the process. This approach has been applied to a multi-robot system and is also effective for both free-flying and articulated robots.</font></p>
<a href="https://github.com/harshkakashaniya/Multiple_Robot_with_PRM" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a>  

</div>
        
    <div class="span5">
      <img src="./img/prm.gif" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Left-project">

<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
      <img src="./img/A_star.png" alt="" title="" class="sidebar__image" />
    </div>
    <div class="span5">
    <h3>Impelementation of Dikstra and A* algorithm on a static environment</h3>
<h3><font color="black">Prog. Lang. Used: Python </font></h3>
    <h3><font color="black">Keywords: Dynamic Planning, A*, Dijkstra, BFS</font></h3>
    <p>Autonomous robots need intelligent path planning to increase the robot's functionality and efficiency. Here a map is given with a source and destination point in a static environment. Path planning includes locating a trajectory that results in the robot reaching the target point when executed. </p>
<p>Dijkstra is a classic algorithm based on breadth first serach for finding the shortest path between two points due to it's optimisation capability. The general idea here is to report vertices in increasing order of their distances from the source vertex while constructing the shortest path tree edge by edge; at each step adding one new edge, corresponding to the construction of the shortest path to the current new vertex. On the other hand, the A* algorithm uses information from both Dijkstra and Greedy Best-First Search. The heuristic here uses information relative to the place where the objective is located to select the next direction to be followed </p>
<a href="https://github.com/harshkakashaniya/Dijkstra-and-A-Algorithm" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 
    </div>
  </div>
</div>
  </section>




<section class="row-fluid">
<div class="Subject-title">
      <div class="container">
        <div class="span12">
          <h2>Optimal Controls </h2>
	  <p>Projects in this section are on different controls and filters.</p>
        </div>
      </div>
    </div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Design and Simulation of LQR (Linear Quadratic Regulator) Controller for a gantry crane</font></h3>
    <p><font color="white"></font></p>

<a href="https://github.com/harshkakashaniya/Double-Pendulum-with-Cart" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
    <div class="span5">
      <img src="./img/Pendulum.gif" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>


<section class="row-fluid">
<div class="Subject-title">
      <div class="container">
        <div class="span12">
          <h2>Robot Modelling </h2>
	  <p>Projects in this section are design of robot with its Inverse and forward kinamatics. </p>
        </div>
      </div>
    </div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Modelling of fruit picking robot</font></h3>
    <p><font color="white">The 3 basic needs of human beings are food, shelter and clothing. Parallel, the world population is also growing at a very steep rate. Hence, natural resources such as land and water is always under continuous stress. Moreover, due to deforestation and global warming cultivable land is decreasing.Hence it is necessary to have effective solutions to iterative tasks like fruit picking, ploughing, sowing etc.So innovation in the agricultural yield will result in great impact on mankind and economy. Articulated robots for fruit picking is a technology that enables autonomy in agriculture processes. As a robotics engineer, I feel it is my moral responsibility to automate arduous jobs done by farmers and increase yield. Hence, this is my motivation to choose the following robot as my modelling project.</font></p>
<p><font color="white">So in this project I worked on designing the robot model with its link length and reach. Then its inverse and forward kinamatics was developed. Which was further used in Matlab to do simulation of whole system. So this project involved full design cycle of Robot.</font></p>


<a href="https://github.com/harshkakashaniya/Fruit-Picking-Robot" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
    <div class="span5">
      <img src="./img/robot.jpg" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>



<section class="row-fluid">
<div class="Subject-title">
      <div class="container">
        <div class="span12">
          <h2>Computer Vision </h2>
	  <p>Projects in this section are mostly on machine learning and Image Processing.</p>
        </div>
      </div>
    </div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Design of Algorithm for Lane Detection and Turn Prediction used in Self Driving Cars</font></h3>
<h3><font color="white">Prog. Lang. Used: Python, OpenCV </font></h3>
    <h3><font color="white">Keywords: Homography, Image Processing, Histogram</font></h3>
    <p><font color="white">The booming topic of self driving car needs no formal introduction. Lane Detection and Turn Prediction being the most fundamental needs of the same. Not RADAR or LIDAR, but it is a front facing camera that can achieve this in the cheapest way. Although we can assume the lanes of the road to be parallel to each other, the challenge is that the actual camera does not look at the road ’from the top’, but it always looks at the
road at the same angle.  </font></p>
<p> <font color="white">In this project the homography is first computed using points from an image frame. Image processing techniques such as Edge Detection, noise removal and extraction of ROI is also performed. Perspective transform is taken to build the Histogram of the Lane Pixels for both the lanes, using the homograpy. Further refining of the lane detection is done by fitting a polynomial in between the lane candidates along with turn prediction.
</font></p>

<a href="https://github.com/harshkakashaniya/Traffic_Lane_Detection" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
    <div class="span5">
      <img src="./img/traffic_lane.jpg" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Left-project">

<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
      <img src="./img/GMM.jpg" alt="" title="" class="sidebar__image" />
    </div>
    <div class="span5">
    <h3>Color segmentation using Gaussian Mixture Models and Expectation Maximization Techniques</h3>
<h3>Prog. Lang. Used: Python, OpenCV </h3>
    <h3>Keywords: Hough Circles, Histogram Equalization , Unsupervised learning</h3>
    <p>In this project the segmentation and detection of under water buoys is done based on color. Conventional segmentation approach cannot be applied here as the environment has a large amount of noise and the light intensities also change continuously, resulting in ineffective thresholding. In such cases we can implement the concept of color segmentation using Gaussian Mixture Models and Expectation Maximization Techniques.</p>
<p>In the above method unsupervised learning is used to teach the model different color distributions. This learned model is used to do the color segmentation. The iterative algorithm EM is implemented using both 1D and 3D Gaussian. In the E-step the probability of the data belonging to different gaussians is
calculated. In the E-step step the new gaussian
parameters are calculated until the convergence is reached. The detection is finally done using OpenCv's Hough Circles.</p>

<a href="https://github.com/harshkakashaniya/GMM-EM_4_Multivarient" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Implementation of Traffic Sign Detection and Classification using MSER and SVM Model</h3>
<h3><font color="white">Prog. Lang. Used: Python, OpenCV </font></h3>
    <h3><font color="white">Keywords: Support Vector Machine, HOG, MSER</font></h3>
    <p><font color="white">The recent reserach in self driving cars has proved that the goal of achieving autonomous driving without collision can not be implemented without the proper recognition of traffic signs. Also the task of understanding the environment can be classified into sub-tasks i.e detection and classification. In this project I have focused on 8 commonly used signs.</font></p>
<p>Post the initial image processing, the Detection of the Signs is achieved using the Maximally Stable External Region (MSER) Algorithm, which is a varient of affine trasnformation. It allows multi-scale detection without any smoothing, which can detect both fine and large structures.
</font></p>
<p><font color="white">The Classifcation phase is implemented using HOG descriptors to train an SVM model with the RBF kernel. Computer Vision techniques is used to get the HOG values. SVM's predict method is then used to check the correctness of the model. The E_out achieved was 97.4% showing that 97% of the images were classified correctly. The code and implementation is show in the links below.
</font></p>
<a href="https://github.com/harshkakashaniya/Traffic_sign_detection" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
    <div class="span5">
      <img src="./img/sign_detect.png" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Left-project">

<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
      <img src="./img/Cube.jpg" alt="" title="" class="sidebar__image" />
    </div>
    <div class="span5">
    <h3>Detection and Tracking of AR Tags using Homography and Pose Estimation</h3>
    <h3>Prog. Lang. Used: Python, OpenCV </h3>
    <h3>Keywords: Homography, AR Tag, Contours, Corner Detection, Projection Matrix</h3>
    <p>In this project I have focused on detecting a custom AR Tag (a form of fiducial marker), that is used for obtaining a point of reference in the real world, such as in augmented reality applications.
The two aspects to using an AR Tag: detection and tracking, has been implemented.</p>
<p>Detection is performed using edge and corner detection. Several methods of Computer Vision such as Contours has been used for the implementation. On successful detection of the corner, perspective transformation is performed which gives the ID of the AR Tag compemsated for any camera rotation in the image. </p>
<p>The tracking of the Tag is visualised using the method of superimposing an image or placing a virtual cube on the tag. This is achieved using homographic transformation between the world coordinates (the reference AR tag) and the image plane (the tag in the image sequence) which gives the projection matrix to place an object on the Tag. The implementation along with the codes have been shown in the links below.</p>
<a href="https://github.com/harshkakashaniya/AR-tag-detection" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
  </div>
</div>
  </section>

<section class="row-fluid">
<div class="Right-project">
<div class="container-fluid">
  <div class="row-fluid">
    <div class="span5 offset1">
    <h3><font color="white">Object Tracking using Lucas Kanade Template Tracker</font></h3>
    <h3><font color="white">Prog. Lang. Used: Python </font></h3>
    <h3><font color="white">Keywords: Optical Flow, Lucas Kanade, HIstogram Equalization</font></h3>
    <p><font color="white"> Optical flow basically is the distribution of apparent velocities of movement of brightness pattern in an image. Sequences of ordered images allow the estimation of motion as either instantaneous image velocities or discrete image displacements. Lucas Kanade is a differential method used for the estimation of the above achieved by combining information from several nearby pixels. Howver this algorithm assumes that the displacement of the image contents between two nearby instants (frames) is small.</font></p>
<p><font color="white">
In this project, the algorithm has been implemented on three video Visual Tracker benchmark database: featuring a car on the road, a human walking, and a box on a table as shown in the BLOG link. 
To initialize the tracker a template has been defined by drawing a bounding box around the object
to be tracked in the first frame of the video. For each of the subsequent frames the tracker updates an
affine transform that warps the current frame so that the template in the first frame is aligned with the warped
current frame.
The tracked has also been made more robust, by incorporating steps to increase
illumination invariance i.e using LAB color space and histogram equalization.
</font></p>
<a href="https://github.com/harshkakashaniya/Lucas_Kanade_image-tracking" class="btn btn-primary page-title__button big-	button">{{ site.version }} Github Link</a> 

    </div>
    <div class="span5">
      <img src="./img/detection.png" alt="" title="" class="sidebar__image" />
    </div>
  </div>
</div>
  </section>



